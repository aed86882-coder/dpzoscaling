# WMT19 ç¿»è¯‘ä»»åŠ¡ä½¿ç”¨æŒ‡å—

å·²æˆåŠŸæ·»åŠ  WMT19 ç¿»è¯‘ä»»åŠ¡æ”¯æŒåˆ° Parallel DistZO2 + DP-AggZO æ¡†æ¶ä¸­ã€‚

---

## ğŸ“‹ æ–°å¢æ–‡ä»¶

1. **`src/wmt19_translation.py`** - WMT19 æ•°æ®é›†ç±»
2. **`src/parallel_distzo2_dp_aggzo_wrapper_seq2seq.py`** - Seq2Seq æ¨¡å‹åŒ…è£…å™¨
3. **`run_parallel_distzo2_dp_aggzo_translation.py`** - ç¿»è¯‘ä»»åŠ¡è®­ç»ƒè„šæœ¬
4. **`examples/parallel_distzo2_dp_aggzo_translation.sh`** - ä¾¿æ·å¯åŠ¨è„šæœ¬

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å¿«é€Ÿæµ‹è¯•ï¼ˆå• GPUï¼Œå°æ¨¡å‹ï¼‰

```bash
cd /root/autodl-tmp/dpscal/opt

CUDA_VISIBLE_DEVICES=0 \
MODEL=facebook/opt-125m \
SOURCE_LANG=en \
TARGET_LANG=zh \
NUM_TRAIN=1000 \
NUM_EVAL=100 \
STEPS=50 \
EVAL_STEPS=10 \
N=8 \
MAX_LENGTH=256 \
DP_SAMPLE_RATE=1.0 \
bash examples/parallel_distzo2_dp_aggzo_translation.sh
```

### 2. æ ‡å‡†è®­ç»ƒï¼ˆå¤š GPUï¼‰

```bash
CUDA_VISIBLE_DEVICES=0,1 \
MODEL=facebook/opt-125m \
SOURCE_LANG=en \
TARGET_LANG=zh \
NUM_TRAIN=10000 \
NUM_EVAL=1000 \
STEPS=1000 \
EVAL_STEPS=100 \
N=16 \
BATCH_SIZE=4 \
MAX_LENGTH=256 \
DP_SAMPLE_RATE=0.064 \
bash examples/parallel_distzo2_dp_aggzo_translation.sh
```

### 3. å¤§è§„æ¨¡è®­ç»ƒï¼ˆå¤§æ¨¡å‹ï¼‰

```bash
CUDA_VISIBLE_DEVICES=0,1,2,3 \
MODEL=facebook/opt-1.3b \
SOURCE_LANG=en \
TARGET_LANG=zh \
NUM_TRAIN=50000 \
NUM_EVAL=5000 \
STEPS=5000 \
EVAL_STEPS=250 \
N=32 \
BATCH_SIZE=4 \
MAX_LENGTH=256 \
DP_SAMPLE_RATE=0.032 \
bash examples/parallel_distzo2_dp_aggzo_translation.sh
```

---

## âš™ï¸ å‚æ•°è¯´æ˜

### æ¨¡å‹é€‰æ‹©

| æ¨¡å‹ | å¤§å° | ç‰¹ç‚¹ | æ¨èåœºæ™¯ |
|------|------|------|----------|
| `facebook/opt-125m` | ~250MB | å°æ¨¡å‹ï¼Œå¿«é€Ÿæµ‹è¯• | å¿«é€Ÿæµ‹è¯• |
| `facebook/opt-1.3b` | ~2.5GB | ä¸­ç­‰æ¨¡å‹ | æ ‡å‡†è®­ç»ƒ |
| `facebook/opt-2.7b` | ~5.4GB | è¾ƒå¤§æ¨¡å‹ | é«˜è´¨é‡è®­ç»ƒ |
| `facebook/opt-6.7b` | ~13GB | å¤§å‹æ¨¡å‹ | æœ€ä½³è´¨é‡ï¼ˆéœ€è¦å¤§ GPUï¼‰ |

### æ•°æ®é›†å‚æ•°

- `SOURCE_LANG`: æºè¯­è¨€ (é»˜è®¤: `en`)
- `TARGET_LANG`: ç›®æ ‡è¯­è¨€ (é»˜è®¤: `zh`)
- `NUM_TRAIN`: è®­ç»ƒæ ·æœ¬æ•° (é»˜è®¤: `10000`)
- `NUM_EVAL`: è¯„ä¼°æ ·æœ¬æ•° (é»˜è®¤: `1000`)

### åºåˆ—é•¿åº¦å‚æ•°

- `MAX_LENGTH`: æ€»åºåˆ—é•¿åº¦ï¼ŒåŒ…æ‹¬ prompt + æºè¯­è¨€ + ç›®æ ‡è¯­è¨€ (é»˜è®¤: `256`)

### DP-AggZO å‚æ•°

- `N`: æ–¹å‘æ•°é‡ (é»˜è®¤: `16`)
- `DP_EPS`: DP epsilon (é»˜è®¤: `2.0`)
- `DP_CLIP`: æ¢¯åº¦è£å‰ªé˜ˆå€¼ (é»˜è®¤: `7.5`)
- `DP_SAMPLE_RATE`: Poisson é‡‡æ ·ç‡ (é»˜è®¤: `0.064`)

---

## ğŸ”§ æ•°æ®é›†åŠ è½½

WMT19 æ•°æ®é›†ä¼šä» HuggingFace è‡ªåŠ¨ä¸‹è½½ã€‚å¦‚æœä¸‹è½½å¤±è´¥ï¼Œä»£ç ä¼šåˆ›å»ºä¸€ä¸ªè™šæ‹Ÿæ•°æ®é›†ç”¨äºæµ‹è¯•ã€‚

### ç¯å¢ƒå˜é‡ï¼ˆå¯é€‰ï¼‰

å¦‚æœ HuggingFace è®¿é—®æœ‰é—®é¢˜ï¼Œå¯ä»¥è®¾ç½®é•œåƒï¼š

```bash
export HF_ENDPOINT=https://hf-mirror.com
export HF_HOME=/root/autodl-tmp/cache/
```

---

## ğŸ“Š ä¸é—®ç­”ä»»åŠ¡çš„ä¸»è¦åŒºåˆ«

| ç‰¹æ€§ | SQuAD (é—®ç­”) | WMT19 (ç¿»è¯‘) |
|------|--------------|--------------|
| **æ¨¡å‹ç±»å‹** | Decoder-only (OPT) | Decoder-only (OPT) |
| **è¾“å…¥æ ¼å¼** | é—®é¢˜ + ä¸Šä¸‹æ–‡ | "Translate en to zh: {source} -> {target}" |
| **è¾“å‡º** | ç­”æ¡ˆæ–‡æœ¬ | ç›®æ ‡è¯­è¨€æ–‡æœ¬ |
| **Wrapper** | `ParallelDistZO2DPAggZOOPT` | `ParallelDistZO2DPAggZOOPT` |
| **Loss** | Cross-entropy | Cross-entropy (only on target part) |
| **è¯„ä¼°æŒ‡æ ‡** | F1 Score | BLEU Score (éœ€è¦é¢å¤–å®ç°) |

---

## ğŸ¯ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### GPU æ•°é‡ä¸æ–¹å‘æ•°åŒ¹é…

å»ºè®® K èƒ½è¢« num_gpus æ•´é™¤ï¼š

| K | æ¨è GPU æ•°é‡ | æ¯ GPU æ–¹å‘æ•° |
|---|--------------|--------------|
| 8 | 1, 2, 4 | 8, 4, 2 |
| 16 | 1, 2, 4 | 16, 8, 4 |
| 32 | 1, 2, 4, 8 | 32, 16, 8, 4 |

### æ˜¾å­˜ä¼˜åŒ–

å¦‚æœé‡åˆ° OOMï¼š

1. å‡å°‘ `BATCH_SIZE` (8 â†’ 4 â†’ 2 â†’ 1)
2. å‡å°‘åºåˆ—é•¿åº¦ (`MAX_SOURCE_LEN`, `MAX_TARGET_LEN`)
3. å‡å°‘æ–¹å‘æ•° `N` (32 â†’ 16 â†’ 8)
4. ä½¿ç”¨æ›´å°çš„æ¨¡å‹

### è®­ç»ƒé€Ÿåº¦

- ç¿»è¯‘ä»»åŠ¡æ¯”åˆ†ç±»ä»»åŠ¡æ…¢ï¼ˆæ›´é•¿åºåˆ—ï¼‰
- å¤š GPU å¯ä»¥æ˜¾è‘—åŠ é€Ÿï¼ˆ3-4xï¼‰
- å»ºè®®è‡³å°‘ä½¿ç”¨ 2 ä¸ª GPU

---

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ¨¡å‹é€‰æ‹©**: å¯ä»¥ä½¿ç”¨ä¸åŒå¤§å°çš„ OPT æ¨¡å‹ï¼Œæ ¹æ®éœ€è¦é€‰æ‹©
2. **åºåˆ—é•¿åº¦**: ç¿»è¯‘ä»»åŠ¡æ ¼å¼ä¸º "Translate X to Y: {source} -> {target}"ï¼Œéœ€è¦è¶³å¤Ÿçš„é•¿åº¦å®¹çº³å®Œæ•´ prompt å’Œç›®æ ‡æ–‡æœ¬
3. **Prompt æ ¼å¼**: ä½¿ç”¨ "->" ä½œä¸ºåˆ†éš”ç¬¦ï¼Œåªå¯¹ç›®æ ‡è¯­è¨€éƒ¨åˆ†è®¡ç®— loss
4. **Tokenization**: OPT ä½¿ç”¨æ ‡å‡†çš„ BPE tokenizerï¼Œæ— éœ€é¢å¤–ä¾èµ–

---

## ğŸ“ ç¤ºä¾‹è¾“å‡º

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šçœ‹åˆ°ï¼š

```
============================================
Parallel DistZO2-DP-AggZO Translation Training Configuration
============================================
World size: 2 GPUs
Model: facebook/mbart-large-cc25
Dataset: WMT19 en-zh
Total directions: 16
Directions per GPU: ~8
DP epsilon: 2.0
DP clip: 7.5
Learning rate: 1e-05
Max steps: 1000
============================================

[Rank 0] Responsible for directions 0-7 (total 8/16)
[Rank 1] Responsible for directions 8-15 (total 8/16)

Step 0: Loss=8.2341
Step 10: Loss=7.9123
...
```

---

## ğŸ”— ç›¸å…³èµ„æº

- **WMT19 æ•°æ®é›†**: https://huggingface.co/datasets/wmt19
- **mBART æ¨¡å‹**: https://huggingface.co/facebook/mbart-large-cc25
- **OPUS-MT æ¨¡å‹**: https://huggingface.co/Helsinki-NLP/opus-mt-en-zh

---

## âœ… æ£€æŸ¥æ¸…å•

è¿è¡Œå‰ç¡®è®¤ï¼š

- [ ] å·²å®‰è£… `datasets` å’Œ `sentencepiece`
- [ ] æœ‰è¶³å¤Ÿçš„ GPU æ˜¾å­˜ï¼ˆå»ºè®®è‡³å°‘ 16GB per GPUï¼‰
- [ ] è®¾ç½®äº†æ­£ç¡®çš„ç¯å¢ƒå˜é‡ï¼ˆå¦‚éœ€è¦ï¼‰
- [ ] é€‰æ‹©äº†åˆé€‚çš„æ¨¡å‹ï¼ˆæµ‹è¯•ç”¨å°æ¨¡å‹ï¼Œè®­ç»ƒç”¨å¤§æ¨¡å‹ï¼‰

